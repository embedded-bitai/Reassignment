{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/bitai/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/bitai/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/bitai/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/bitai/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/bitai/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/bitai/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/bitai/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/bitai/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/bitai/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/bitai/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/bitai/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/bitai/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# feature extractoring and preprocessing data\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import csv\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#Keras\n",
    "import keras\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmap = plt.get_cmap('inferno')\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
    "for g in genres:\n",
    "    pathlib.Path(f'img_data/{g}').mkdir(parents=True, exist_ok=True)     \n",
    "    for filename in os.listdir(f'./MIR/genres/{g}'):\n",
    "        songname = f'./MIR/genres/{g}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=5)\n",
    "        plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
    "        plt.axis('off');\n",
    "        plt.savefig(f'img_data/{g}/{filename[:-3].replace(\".\", \"\")}.png')\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "for i in range(1, 21):\n",
    "    header += f' mfcc{i}'\n",
    "header += ' label'\n",
    "header = header.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data.csv', 'w', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
    "for g in genres:\n",
    "    for filename in os.listdir(f'./MIR/genres/{g}'):\n",
    "        songname = f'./MIR/genres/{g}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=30)\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        #rmse = mean_squared_error(y, y_pred=sr)**0.5\n",
    "        rmse = librosa.feature.rms(y=y)\n",
    "        to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        to_append += f' {g}'\n",
    "        file = open('data.csv', 'a', newline='')\n",
    "        with file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(to_append.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>rmse</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "      <th>mfcc14</th>\n",
       "      <th>mfcc15</th>\n",
       "      <th>mfcc16</th>\n",
       "      <th>mfcc17</th>\n",
       "      <th>mfcc18</th>\n",
       "      <th>mfcc19</th>\n",
       "      <th>mfcc20</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues.00061.wav</td>\n",
       "      <td>0.451905</td>\n",
       "      <td>0.141766</td>\n",
       "      <td>2504.026852</td>\n",
       "      <td>2180.438691</td>\n",
       "      <td>5077.152632</td>\n",
       "      <td>0.167584</td>\n",
       "      <td>-82.454712</td>\n",
       "      <td>94.147758</td>\n",
       "      <td>-27.120918</td>\n",
       "      <td>...</td>\n",
       "      <td>8.139763</td>\n",
       "      <td>-8.494857</td>\n",
       "      <td>8.283360</td>\n",
       "      <td>-10.346549</td>\n",
       "      <td>-3.462061</td>\n",
       "      <td>-5.223508</td>\n",
       "      <td>-2.595848</td>\n",
       "      <td>-8.363733</td>\n",
       "      <td>-6.978243</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blues.00020.wav</td>\n",
       "      <td>0.302732</td>\n",
       "      <td>0.075387</td>\n",
       "      <td>1389.955510</td>\n",
       "      <td>1911.485152</td>\n",
       "      <td>3005.773491</td>\n",
       "      <td>0.052560</td>\n",
       "      <td>-230.412994</td>\n",
       "      <td>127.094185</td>\n",
       "      <td>7.151100</td>\n",
       "      <td>...</td>\n",
       "      <td>2.561243</td>\n",
       "      <td>-4.329453</td>\n",
       "      <td>6.817760</td>\n",
       "      <td>-6.157660</td>\n",
       "      <td>-6.214757</td>\n",
       "      <td>-4.515433</td>\n",
       "      <td>-1.850599</td>\n",
       "      <td>-0.539056</td>\n",
       "      <td>1.508026</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blues.00051.wav</td>\n",
       "      <td>0.393756</td>\n",
       "      <td>0.196723</td>\n",
       "      <td>1977.172377</td>\n",
       "      <td>1927.803692</td>\n",
       "      <td>3942.834492</td>\n",
       "      <td>0.106627</td>\n",
       "      <td>-55.579243</td>\n",
       "      <td>114.935852</td>\n",
       "      <td>-37.052830</td>\n",
       "      <td>...</td>\n",
       "      <td>12.782317</td>\n",
       "      <td>-16.528681</td>\n",
       "      <td>3.793787</td>\n",
       "      <td>-7.890871</td>\n",
       "      <td>8.477611</td>\n",
       "      <td>-4.065210</td>\n",
       "      <td>3.207442</td>\n",
       "      <td>-5.178251</td>\n",
       "      <td>-1.279523</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues.00077.wav</td>\n",
       "      <td>0.408876</td>\n",
       "      <td>0.243217</td>\n",
       "      <td>2206.771246</td>\n",
       "      <td>2191.473506</td>\n",
       "      <td>4657.388504</td>\n",
       "      <td>0.111526</td>\n",
       "      <td>-29.010990</td>\n",
       "      <td>104.532921</td>\n",
       "      <td>-30.974205</td>\n",
       "      <td>...</td>\n",
       "      <td>10.786453</td>\n",
       "      <td>-10.558812</td>\n",
       "      <td>6.877709</td>\n",
       "      <td>-10.294858</td>\n",
       "      <td>6.967846</td>\n",
       "      <td>-10.256099</td>\n",
       "      <td>0.705014</td>\n",
       "      <td>-6.000722</td>\n",
       "      <td>1.348955</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blues.00087.wav</td>\n",
       "      <td>0.336773</td>\n",
       "      <td>0.158098</td>\n",
       "      <td>1442.190271</td>\n",
       "      <td>1870.534155</td>\n",
       "      <td>3083.414688</td>\n",
       "      <td>0.050889</td>\n",
       "      <td>-155.504929</td>\n",
       "      <td>125.638863</td>\n",
       "      <td>1.596553</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.792893</td>\n",
       "      <td>-7.748057</td>\n",
       "      <td>0.413548</td>\n",
       "      <td>-7.030263</td>\n",
       "      <td>3.997679</td>\n",
       "      <td>-6.256611</td>\n",
       "      <td>0.958227</td>\n",
       "      <td>2.019821</td>\n",
       "      <td>-5.742188</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename  chroma_stft      rmse  spectral_centroid  \\\n",
       "0  blues.00061.wav     0.451905  0.141766        2504.026852   \n",
       "1  blues.00020.wav     0.302732  0.075387        1389.955510   \n",
       "2  blues.00051.wav     0.393756  0.196723        1977.172377   \n",
       "3  blues.00077.wav     0.408876  0.243217        2206.771246   \n",
       "4  blues.00087.wav     0.336773  0.158098        1442.190271   \n",
       "\n",
       "   spectral_bandwidth      rolloff  zero_crossing_rate       mfcc1  \\\n",
       "0         2180.438691  5077.152632            0.167584  -82.454712   \n",
       "1         1911.485152  3005.773491            0.052560 -230.412994   \n",
       "2         1927.803692  3942.834492            0.106627  -55.579243   \n",
       "3         2191.473506  4657.388504            0.111526  -29.010990   \n",
       "4         1870.534155  3083.414688            0.050889 -155.504929   \n",
       "\n",
       "        mfcc2      mfcc3  ...     mfcc12     mfcc13    mfcc14     mfcc15  \\\n",
       "0   94.147758 -27.120918  ...   8.139763  -8.494857  8.283360 -10.346549   \n",
       "1  127.094185   7.151100  ...   2.561243  -4.329453  6.817760  -6.157660   \n",
       "2  114.935852 -37.052830  ...  12.782317 -16.528681  3.793787  -7.890871   \n",
       "3  104.532921 -30.974205  ...  10.786453 -10.558812  6.877709 -10.294858   \n",
       "4  125.638863   1.596553  ...  -0.792893  -7.748057  0.413548  -7.030263   \n",
       "\n",
       "     mfcc16     mfcc17    mfcc18    mfcc19    mfcc20  label  \n",
       "0 -3.462061  -5.223508 -2.595848 -8.363733 -6.978243  blues  \n",
       "1 -6.214757  -4.515433 -1.850599 -0.539056  1.508026  blues  \n",
       "2  8.477611  -4.065210  3.207442 -5.178251 -1.279523  blues  \n",
       "3  6.967846 -10.256099  0.705014 -6.000722  1.348955  blues  \n",
       "4  3.997679  -6.256611  0.958227  2.019821 -5.742188  blues  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 28)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unneccesary columns\n",
    "data = data.drop(['filename'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_list = data.iloc[:, -1]\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(genre_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.84236989,  0.92287085,  2.35855648,  1.95610118,  2.21430833,\n",
       "        2.09035242,  0.91790935, -1.98182487,  1.06244477, -1.0872832 ,\n",
       "        1.4675165 , -0.73282042,  1.16466683, -0.70750656,  0.79220495,\n",
       "       -0.56810447,  0.3069385 , -0.42743785,  0.82600079, -0.3880957 ,\n",
       "        0.68975655, -0.58861142,  1.32844375,  0.18445546,  1.84079664,\n",
       "        0.71231544])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bitai/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/bitai/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/bitai/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bitai/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/bitai/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bitai/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/bitai/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 2.1563 - acc: 0.2263\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 45us/step - loss: 1.8502 - acc: 0.3887\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 30us/step - loss: 1.6190 - acc: 0.4163\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 28us/step - loss: 1.4466 - acc: 0.4863\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 15us/step - loss: 1.3198 - acc: 0.5587\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 11us/step - loss: 1.2189 - acc: 0.5663\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 14us/step - loss: 1.1357 - acc: 0.5988\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 14us/step - loss: 1.0649 - acc: 0.6450\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 11us/step - loss: 1.0059 - acc: 0.6625\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 13us/step - loss: 0.9525 - acc: 0.6925\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 13us/step - loss: 0.9039 - acc: 0.7025\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 12us/step - loss: 0.8633 - acc: 0.7150\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 13us/step - loss: 0.8188 - acc: 0.7350\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 14us/step - loss: 0.7868 - acc: 0.7425\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 12us/step - loss: 0.7527 - acc: 0.7475\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 12us/step - loss: 0.7272 - acc: 0.7575\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 13us/step - loss: 0.7033 - acc: 0.7688\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 12us/step - loss: 0.6679 - acc: 0.7737\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 12us/step - loss: 0.6405 - acc: 0.7925\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 11us/step - loss: 0.6022 - acc: 0.8125\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 115us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc:  0.73\n"
     ]
    }
   ],
   "source": [
    "print('test_acc: ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = X_train[:200]\n",
    "partial_x_train = X_train[200:]\n",
    "\n",
    "y_val = y_train[:200]\n",
    "partial_y_train = y_train[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 600 samples, validate on 200 samples\n",
      "Epoch 1/30\n",
      "600/600 [==============================] - 0s 341us/step - loss: 2.2897 - acc: 0.1167 - val_loss: 2.1786 - val_acc: 0.2650\n",
      "Epoch 2/30\n",
      "600/600 [==============================] - 0s 14us/step - loss: 2.1257 - acc: 0.3317 - val_loss: 2.0688 - val_acc: 0.3150\n",
      "Epoch 3/30\n",
      "600/600 [==============================] - 0s 15us/step - loss: 1.9839 - acc: 0.4133 - val_loss: 1.9469 - val_acc: 0.3100\n",
      "Epoch 4/30\n",
      "600/600 [==============================] - 0s 17us/step - loss: 1.8296 - acc: 0.4067 - val_loss: 1.8256 - val_acc: 0.3150\n",
      "Epoch 5/30\n",
      "600/600 [==============================] - 0s 13us/step - loss: 1.6836 - acc: 0.4150 - val_loss: 1.7084 - val_acc: 0.3500\n",
      "Epoch 6/30\n",
      "600/600 [==============================] - 0s 17us/step - loss: 1.5413 - acc: 0.4633 - val_loss: 1.6188 - val_acc: 0.4150\n",
      "Epoch 7/30\n",
      "600/600 [==============================] - 0s 12us/step - loss: 1.4307 - acc: 0.5100 - val_loss: 1.5584 - val_acc: 0.4350\n",
      "Epoch 8/30\n",
      "600/600 [==============================] - 0s 14us/step - loss: 1.3362 - acc: 0.5333 - val_loss: 1.5068 - val_acc: 0.4550\n",
      "Epoch 9/30\n",
      "600/600 [==============================] - 0s 11us/step - loss: 1.2556 - acc: 0.5433 - val_loss: 1.4741 - val_acc: 0.4700\n",
      "Epoch 10/30\n",
      "600/600 [==============================] - 0s 16us/step - loss: 1.2024 - acc: 0.5833 - val_loss: 1.4555 - val_acc: 0.4750\n",
      "Epoch 11/30\n",
      "600/600 [==============================] - 0s 12us/step - loss: 1.1433 - acc: 0.5983 - val_loss: 1.4419 - val_acc: 0.5200\n",
      "Epoch 12/30\n",
      "600/600 [==============================] - 0s 16us/step - loss: 1.0761 - acc: 0.6267 - val_loss: 1.4268 - val_acc: 0.5050\n",
      "Epoch 13/30\n",
      "600/600 [==============================] - 0s 12us/step - loss: 1.0272 - acc: 0.6500 - val_loss: 1.3786 - val_acc: 0.5450\n",
      "Epoch 14/30\n",
      "600/600 [==============================] - 0s 12us/step - loss: 0.9723 - acc: 0.6783 - val_loss: 1.3623 - val_acc: 0.5200\n",
      "Epoch 15/30\n",
      "600/600 [==============================] - 0s 16us/step - loss: 0.9400 - acc: 0.6867 - val_loss: 1.3410 - val_acc: 0.5750\n",
      "Epoch 16/30\n",
      "600/600 [==============================] - 0s 13us/step - loss: 0.8821 - acc: 0.7000 - val_loss: 1.3599 - val_acc: 0.5800\n",
      "Epoch 17/30\n",
      "600/600 [==============================] - 0s 12us/step - loss: 0.8603 - acc: 0.6983 - val_loss: 1.3182 - val_acc: 0.5850\n",
      "Epoch 18/30\n",
      "600/600 [==============================] - 0s 16us/step - loss: 0.8224 - acc: 0.7233 - val_loss: 1.2646 - val_acc: 0.5850\n",
      "Epoch 19/30\n",
      "600/600 [==============================] - 0s 14us/step - loss: 0.7897 - acc: 0.7367 - val_loss: 1.2845 - val_acc: 0.5650\n",
      "Epoch 20/30\n",
      "600/600 [==============================] - 0s 13us/step - loss: 0.7486 - acc: 0.7517 - val_loss: 1.3470 - val_acc: 0.5650\n",
      "Epoch 21/30\n",
      "600/600 [==============================] - 0s 14us/step - loss: 0.7371 - acc: 0.7533 - val_loss: 1.3236 - val_acc: 0.5850\n",
      "Epoch 22/30\n",
      "600/600 [==============================] - 0s 11us/step - loss: 0.7123 - acc: 0.7517 - val_loss: 1.2596 - val_acc: 0.5950\n",
      "Epoch 23/30\n",
      "600/600 [==============================] - 0s 13us/step - loss: 0.6772 - acc: 0.7767 - val_loss: 1.2605 - val_acc: 0.5850\n",
      "Epoch 24/30\n",
      "600/600 [==============================] - 0s 15us/step - loss: 0.6618 - acc: 0.7717 - val_loss: 1.2853 - val_acc: 0.5800\n",
      "Epoch 25/30\n",
      "600/600 [==============================] - 0s 14us/step - loss: 0.6487 - acc: 0.7800 - val_loss: 1.3147 - val_acc: 0.5900\n",
      "Epoch 26/30\n",
      "600/600 [==============================] - 0s 14us/step - loss: 0.6131 - acc: 0.8117 - val_loss: 1.3265 - val_acc: 0.6000\n",
      "Epoch 27/30\n",
      "600/600 [==============================] - 0s 14us/step - loss: 0.5971 - acc: 0.8033 - val_loss: 1.2807 - val_acc: 0.6000\n",
      "Epoch 28/30\n",
      "600/600 [==============================] - 0s 12us/step - loss: 0.5631 - acc: 0.8283 - val_loss: 1.2866 - val_acc: 0.5800\n",
      "Epoch 29/30\n",
      "600/600 [==============================] - 0s 14us/step - loss: 0.5477 - acc: 0.8350 - val_loss: 1.2839 - val_acc: 0.5750\n",
      "Epoch 30/30\n",
      "600/600 [==============================] - 0s 13us/step - loss: 0.5210 - acc: 0.8550 - val_loss: 1.2990 - val_acc: 0.5900\n",
      "200/200 [==============================] - 0s 19us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=30,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.857143030166626, 0.67]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999994"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
